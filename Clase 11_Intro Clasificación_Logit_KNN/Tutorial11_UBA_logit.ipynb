{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbQnrDd5kPBV"
   },
   "source": [
    "# Big Data y Machine learning (UBA) 2025\n",
    "## Tutorial 11 - Clasificacion 1: Logit & Vecinos Cercanos(KNN)\n",
    "\n",
    "**Objetivo:** entender la \"diferencia\" entre clasificación y regresión. Utilizar Bayes, logit y KNN. \n",
    "\n",
    "Veremos:\n",
    "- Clasificación\n",
    "- Medidas de precisión\n",
    "- KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCC29krdkPBZ"
   },
   "outputs": [],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score \n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tdJMCuTkPBb"
   },
   "source": [
    "#### Nueva situación: '*y*' es una variable cualitativa. ¿Qué hacer? \n",
    "\n",
    "- ¿Por qué en el caso de '*y*' cualitativa la regresión linear no es una opción apropiada?\n",
    "\n",
    "1. Puede no haber una forma de transformar una variable cualitativa con más de 2 niveles en una variable cuantitaiva que nos 'sirva' para una regresión lineal. Puede que '*y*' no tenga un orden. Por ejemplo, si la 'y' hace referencia a enfermedades. ¿Cómo asignarles un valor? Implicaría asumir un orden y también que la diferencia entre las enfermedades es equivalente...\n",
    "\n",
    "2. En el caso binario (2 niveles) podemos transformar la variable a una variable numérica. Por ejemplo: $y=1$ pobre e $y=0$ no pobre. Sin embargo, con una regresión  lineal podría ocurrir que generemos predicciones fuera del intervalo $[0, 1]$ y por ende no podremos interpretarlo como probabilidades...\n",
    "\n",
    "Entonces...\n",
    "#### Vamos a clasificar 'y' (variable cualitativa) en base a 'x'\n",
    "\n",
    "- ¿Estamos ante un caso de aprendizaje supervisado o no supervisado? \n",
    "\n",
    "Vamos a trabajar con bases donde tenemos el output esperado. Por lo tanto, nuestros modelos serán casos de aprendizaje supervisado.\n",
    "     \n",
    "- ¿Qué es el clasificador de Bayes? \n",
    "\n",
    "Clasificar según el estado más probable minimiza el riesgo esperado. Por ej: si la probabilidad de que una persona me pague un credito es mayor que 0.5, predigo que pagará el credito. \n",
    "\n",
    "#### Modelos en esta tutorial:\n",
    "    \n",
    "1. Regresión logística \n",
    "2. KNN\n",
    "\n",
    "Vamos a construir un clasificador con los datos de training. Queremos que funcione bien no solo en el conjunto de entrenamiento sino también en el conjunto de test (datos *nuevos*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGRESIÓN LOGÍSTICA CON SCIKIT-LEARN\n",
    "\n",
    "Algoritmo de clasificación que se usa para predecir la probabilidad de una variable dependiente categórica. El modelo logit predice $P(Y=1)$ como una función de $X$. Se modela la probabilidad de una forma tal que los outputs serán valores entre 0 y 1 para cualquier valor de $X$.\n",
    "\n",
    "\n",
    "Ahora utilizaremos la función [LogisticRegression()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "Se pueden proveer muchos parámetros opcionales para esta función:\n",
    "\n",
    "- **fit_intercept**: Boolean que decide si calcular el intercepto (True) o considerarlo igual a cero (False). Por default es True.\n",
    "- **penalty**: Se determina se usar algún tipo de regularización (lo veremos mas adelante en el curso). Posibles valores: ‘l1’, ‘l2’, ‘elasticnet’ y 'None' (usaremos esta opción por ahora). El valor por defecto es default es ‘l2’, es decir que se aplica regularización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKjyS79GkPBc"
   },
   "outputs": [],
   "source": [
    "# Creamos un vector de x e y para fines del ejemplo.\n",
    "np.random.seed(25)\n",
    "X = np.random.normal(size=5000)\n",
    "print(X)\n",
    "\n",
    "# Recordatorio: para la regresión lineal creamos un vector aleatorio así:\n",
    "y_int = 2 + 3*X + np.random.rand(500, 1)\n",
    "\n",
    "# Ahora lo crearemos de la siguiente forma para que tenga más sentido usar una regresión logística\n",
    "y = (X > 0).astype(float) # si no pusiera astype sería un array de True y False\n",
    "\n",
    "# Alteramos los valores de X y sumamos variación con el \"error\"\n",
    "X[X > 0] *= 25\n",
    "X += .5 * np.random.normal(size=5000)\n",
    "X = X.reshape((-1, 1)) # para tenerlo como columna\n",
    "print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4I__jLCpkPBd",
    "outputId": "28b640d8-4491-4fc6-e4c1-a64057a16ca7"
   },
   "outputs": [],
   "source": [
    "# Graficamos para ver si nos quedó un vector que 1s y 0s\n",
    "plt.scatter(X, y, color='orange', zorder=20, marker=\"|\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimación de Regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irnHZgZbkPBe",
    "outputId": "5c14ea37-11ca-43fc-fd6a-1ea7430277b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ajustamos el clasificador con el método fit() \n",
    "log_reg = LogisticRegression(penalty=None).fit(X, y)\n",
    "\n",
    "# Estimacion de los coeficientes\n",
    "print(log_reg.coef_)\n",
    "print(log_reg.intercept_)\n",
    "\n",
    "# Predicciones (probabilidad)\n",
    "y_pred_score = log_reg.predict_proba(X)[:,1]   \n",
    "\n",
    "# Gráfico de resultados\n",
    "plt.figure(figsize=(4,2))\n",
    "\n",
    "# Ordenamos los valores de X\n",
    "X_sorted=np.sort(X, axis=0).flatten()\n",
    "# Predicciones ordenadas (probabilidad)\n",
    "y_pred_score_sorted = log_reg.predict_proba(X_sorted.reshape(-1,1))[:,1]   \n",
    "\n",
    "plt.plot(X_sorted, y_pred_score_sorted, color='blue', zorder=10)\n",
    "plt.scatter(X, y, color='orange', zorder=20, marker=\"|\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Prob(y=1|X)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ejercicio*: Probar con mejorar la visualización de los graficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción de $\\hat{Y}=1$ o $\\hat{Y}=0$ usando el modelo estimado de regresión logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADgZMAw_kPBe",
    "outputId": "140f7389-7777-4563-bbfd-6f8079fe87fd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convertimos las probabilidades en Y con valores 1 o 0 (usando el clasificador de Bayes)\n",
    "y_pred = np.where(y_pred_score > 0.5, 1, y_pred_score)\n",
    "y_pred = np.where(y_pred_score <= 0.5, 0, y_pred)\n",
    "\n",
    "# Con este grafico visualizamos 'y' observado e 'y' predicho\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(X, y_pred, color='red', alpha=0.3, zorder=20)\n",
    "plt.scatter(X, y, color='green', zorder=20, marker=\"|\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Nk2FQwEkPBf",
    "outputId": "9525ef11-dbf9-4eef-e61b-3057037ea524",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Equivalente a lo anterior es usar predict() (clasifica en 0s y 1s)\n",
    "y_pred_2 = log_reg.predict(X)\n",
    "print(pd.crosstab(index=y_pred, columns=y_pred_2)) #tabla para chequear que la prediccion es igual\n",
    "\n",
    "# Y graficamos los resultados\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(X, y_pred_2, color='red', alpha=0.3, zorder=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGRESIÓN LOGÍSTICA CON STATSMODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYIj_a2nkPBf",
    "outputId": "dc43f14e-f668-429c-9717-c1f67c9c4db7"
   },
   "outputs": [],
   "source": [
    "# Podemos repetirlo con statsmodels\n",
    "# Primero agregamos la columna de 1s y hacemos el ajuste\n",
    "X_sm = sm.add_constant(X) \n",
    "logit_model = sm.Logit(y, X_sm)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2()) \n",
    "#También podríamos vn: print(result.summary2().as_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb5paFYmkPBg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_score_sm = result.predict(X_sm)\n",
    "\n",
    "# El método where requiere una condición como primer parámetro, \n",
    "# que cuando es True devuelve el segundo valor y cuando es False devuelve tercero. \n",
    "y_pred_sm = np.where(y_pred_score_sm > 0.5, 1, y_pred_score_sm)\n",
    "y_pred_sm = np.where(y_pred_score_sm <= 0.5, 0, y_pred_sm)\n",
    "\n",
    "print(pd.crosstab(index=y_pred, columns=y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeAbfCsAkPBg"
   },
   "source": [
    "### Medidas de precisión \n",
    "\n",
    "Dependiendo la prioridad del problema seguramente vamos a querer usar diferentes métricas. Scikit learn tiene muchas métricas que pueden explorar en el módulo [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "- Sensitivity o Recall o True Positive Rate: TP rate = TP/P\n",
    "- Specificity o True Negative Rate: 1 - FP rate = TN/N\n",
    "- False Positive Rate o False Alarm Rate: FP rate = FP/N\n",
    "- False Negative Rate: FN rate = FN/P\n",
    "- Precision o Positive Predicted Value: TP/(TP+FP)\n",
    "- Accuracy: (TP+TN)/(P+N)\n",
    "\n",
    "Nota: Cuidado con las traducciones! \"Accuracy\" lo pueden encontrar traducido como \"precisión\" y eso puede generar confusión con la medida \"precision\" (o positive predicted value). Mi sugerencia es traducir \"accuracy\" como \"exactitud\".\n",
    "\n",
    "\n",
    "[Matriz de confusión](https://www.unite.ai/what-is-a-confusion-matrix/)\n",
    "<center>\n",
    "<img src=\"https://www.unite.ai/wp-content/uploads/2019/12/Preventive_Medicine-e1576294312614.png\" width=\"1000\">\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfTtD3wGkPBh",
    "outputId": "cfc2fc2d-aeb5-43f6-9dfa-a87d5403f1f1"
   },
   "outputs": [],
   "source": [
    "matriz_confusion = confusion_matrix(y, y_pred)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(matriz_confusion) \n",
    "print('Accuracy Score:', accuracy_score(y, y_pred))\n",
    "\n",
    "# Nota importante: en Python la matriz de confusión tiene:\n",
    "# en las filas los valores ciertos\n",
    "# y en las columnas los valores predichos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión de sklearn pone en las filas las Y reales y las columnas las Y predichas. Muestra así los valores:\n",
    "\n",
    "                               predicción\n",
    "                         real   tn fp\n",
    "                                fn tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3TW-0AdkPBh",
    "outputId": "4ea0980b-afbc-4ca0-c0a8-d8763a64de05"
   },
   "outputs": [],
   "source": [
    "# Para los casos donde la predición (la y) es binaria podemos usar lo siguiente:\n",
    "tn, fp , fn, tp = confusion_matrix(y, y_pred).ravel()   # Ravel transforma la matriz en un 1D array\n",
    "# equivalente a: [tn, fp] , [fn, tp] = confusion_matrix(y, y_pred_2)\n",
    "\n",
    "print(\"Verdadero 0: \", tn)\n",
    "print(\"Falso 1: \", fp)\n",
    "print(\"Falso 0: \", fn)\n",
    "print(\"Verdadero 1: \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# recall: tp / p = tp / (tp + fn)\n",
    "recall = recall_score(y, y_pred)\n",
    "print('Recall: %f' % recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwDo6nkMkPBk"
   },
   "source": [
    "#### Repitamos el ejercicio usando el enfoque de validación\n",
    "Vamos a partir la base en entrenamiento (train) y testeo (test) para evaluar nuestra predicción afuera de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gjh24LLkPBl"
   },
   "outputs": [],
   "source": [
    "# Entrenaremos con el 70% de la base de datos y el resto se usarán para testear \n",
    "# el modelo obtenido\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=102)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos la dimension de los vectores creados\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eYHGsJrkPBl"
   },
   "outputs": [],
   "source": [
    "# Estimo:\n",
    "\n",
    "# Ajustamos el clasificador con el metodo fit() \n",
    "log_reg = LogisticRegression(penalty=None).fit(X_train, y_train)\n",
    "\n",
    "# Predecimos probabilidad p sombrero, 'y' sobrero con la muestra de testeo\n",
    "y_train_pred_score = log_reg.predict_proba(X_train)[:,1]\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "\n",
    "\n",
    "y_test_pred_score = log_reg.predict_proba(X_test)[:,1]\n",
    "y_test_pred = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los resultados *adentro de la muestra*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2n1TZMukPBl",
    "outputId": "2f4b5060-bad3-4af3-8581-0bb3f12c9d90"
   },
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print('Accuracy Test: %f' % accuracy)\n",
    "\n",
    "# recall: tp / p = tp / (tp + fn)\n",
    "recall = recall_score(y_train, y_train_pred)\n",
    "print('Recall Test: %f' % recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los resultados *afuera de la muestra*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2n1TZMukPBl",
    "outputId": "2f4b5060-bad3-4af3-8581-0bb3f12c9d90"
   },
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('Accuracy Test: %f' % accuracy)\n",
    "\n",
    "# recall: tp / p = tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print('Recall Test: %f' % recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**: Cómo es la performance afuera vs adentro de la muestra? Por qué es distinto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQKS6N3LkPBo"
   },
   "source": [
    "### Vecinos Cercanos (k-nearest neighbors, KNN)\n",
    "[KNeighborsClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier): Clasificador de vecinos más cercanos\n",
    "\n",
    "A continuación veremos un ejemplo de clasificación de las flores en la base de datos iris nuevamente y probaremos ajustando el parámetro k (cantidad de vecinos) para obtener el modelo con mayor precisión\n",
    "\n",
    "Fuente: [MachineLearning — KNN using scikit-learn](https://towardsdatascience.com/knn-using-scikit-learn-c6bed765be75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvnREjWVkPBm"
   },
   "source": [
    "#### Repaso del dataset de flores iris \n",
    "Esta base de datos la vimos en la tutorial de Cluster (y es un ejemplo muy usado para aprender las funciones de sklearn)\n",
    "\n",
    "[The Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "#print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos respuesta 'y' de los predictores X\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = iris.target_names\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la muestra en datos de entrenamiento y de validación \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape) #vemos lo tamaños de cada subconjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3SBfD-nkPBo"
   },
   "outputs": [],
   "source": [
    "# Vamos a probar con distintos tamaños de k (cantidad de vecinos)\n",
    "k_range = range(1,10)\n",
    "scores = {}      # Para guardar la accuracy en un diccionario\n",
    "scores_list = [] # Para guardar la accuracy en una lista\n",
    "for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred_knn = knn.predict(X_test)\n",
    "        scores[k] = accuracy_score(y_test, y_pred_knn)\n",
    "        scores_list.append(accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vFG6-2FkPBp",
    "outputId": "2cc1875d-7cde-4dde-e3ad-7b57c199f692"
   },
   "outputs": [],
   "source": [
    "# Observemos el diccionario con las métricas\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuHyhYbNkPBp",
    "outputId": "c9ea5eba-d527-4388-efa3-5a82d3288ef5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficamos la precisión en base a la cantidad de vecinos\n",
    "plt.plot(k_range, scores_list)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWfxBzLRkPBp"
   },
   "source": [
    "Los valores de K entre 3 y 10 tienen la misma precisión, que es 97,77, por lo que podemos usar cualquier valor de esos. Elegiremos K = 3 como nuestro modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb1HRoz7kPBp",
    "outputId": "6b0abb95-f4ee-4339-c7e8-74811e4b2f57"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REZe3BpGkPBp",
    "outputId": "36e4e17f-4e9a-4a29-a76b-6a11392b0b11"
   },
   "outputs": [],
   "source": [
    "y_test_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_test_pred_knn)\n",
    "print(\"La exactitud del modelo es: %.3f\" %accuracy_knn)  \n",
    "\n",
    "# Matriz de confusion\n",
    "print(pd.crosstab(index=y_test, columns=y_test_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
